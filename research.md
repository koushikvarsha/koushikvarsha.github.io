---
title: "Research Projects"
author_profile: true
---
<style>

.journal {
        background-color: #FBD603;
        height: 30px;
        width: 75px;
        margin: 2px;
        border: 1px;
        text-align: center;
      }

  .conference{
    background-color: #F0BFB4 ;
    height: 30px;
    width: 105px;
    margin: 2px;
    border: 1px;
    text-align: center;
  }

  .demo{
    background-color: #B9B4F0  ;
    height: 30px;
    width: 65px;
    margin: 2px;
    border: 1px;
    text-align: center;

  }

  .article{
    background-color: #33FFBB;
    height: 30px;
    width: 70px;
    margin: 2px;
    border: 1px;
    text-align: center;
  }
  .workshop{
      background-color: #C3F0B4;
      height: 30px;
      width: 95px;
      margin: 2px;
      border: 1px;
      text-align: center;
  }
  .news{
    background-color: #B4C9F0;
    height: 30px;
    width: 60px;
    margin: 2px;
    border: 1px;
    text-align: center;
  }
  .poster{
    background-color: #F0E2B4;
    height: 30px;
    width: 70px;
    margin: 2px;
    border: 1px;
    text-align: center;
  }
</style>

# <span style = "color: #8E3106"><u>Customizable Smart Devices for Everyday Living</u></span>
_2019-present_

People with cognitive disabilities often face difficulties in remembering, learning, and making decisions, which can impact their everyday activities. To overcome challenges, individuals use reminder applications on handheld devices, like smartphones or tablets. However, these multipurpose devices are compact and can easily be misplaced. Furthermore, individuals need to constantly pause their tasks to view instructions on these devices. Repeatedly switching contexts can negatively impact their ability to complete tasks and may result in discontinued practice or abandonment. Smart home devices, like voice assistants and “smart” appliances, are promising solutions to naturally integrate prompts within everyday activities. Specifically, Augmented Reality (AR) based smart assistants can situate visual information in the location of tasks; thereby, reducing the amount of contextual switching between tasks and assistive devices. Besides contextual prompts, individuals often require devices that adapt support based on their abilities. Therefore, smart devices could combine contextualization and customization by embodying individualized AR-based prompts and feedback. One approach to support customization is to allow individuals to write rules or algorithms on how devices should support them. Introductory block-based programming tools can enable people with cognitive disabilities to write algorithms and reflect on support for everyday tasks.

<div class="journal">
<p><span style = "color: #8E3106">journal</span></p>
</div>
_Towards augmented reality coaching for daily routines: Participatory design with individuals with cognitive disabilities and their caregivers_<br>
_**Varsha Koushik** and Shaun K.Kane, International Journal of Human-Computer Studies, 2022_<br>
[paper link](https://doi.org/10.1016/j.ijhcs.2022.102862)

# <span style="color:#062F8E"><u>Accessible Introductory Programming</u></span>
## <span style="color:#062F8E">StoryBlocks</span>
_2017-2018_
Block based languages like Scratch, Blockly, MIT App Inventor, Snap etc. are widely popular as a first step towards traditional programming. They offer many benefits including simpler syntax, easier interactions, and support creativity and expression through games, animations, stories and other interactive media. However, these visual based languages are not accessible to people with visual impairments, and thus they limit access to introductory programming tools. In this research, I have designed a tangible programming game called StoryBlocks, which uses physical blocks to create story programs, and the physical stories are converted to audio stories with different voices and sound effects using computer vision. This multimodal interface has been designed to support collaborative activities around introductory computing in K-12 classrooms.

<div class="conference">
<p><span style="color:#062F8E">conference</span></p>
</div>
_StoryBlocks: A Tangible Programming Game to Create Accessible Audio Stories_<br>
_**Varsha Koushik**, Darren Guinness, and Shaun K. Kane. 2019. StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI '19)._ **Best Paper Honorable Mention Award** [_top 5%_]<br>
[ACM paper](https://dl.acm.org/doi/10.1145/3290605.3300722)


<div class="demo">
<p><span style="color:#062F8E">demo</span></p>
</div>
_Tangibles + Programming + Audio Stories = Fun_<br>
_**Varsha Koushik** and Shaun K. Kane. 2017. Tangibles + Programming + Audio Stories = Fun. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS '17)._<br>
[ACM paper](https://dl.acm.org/doi/abs/10.1145/3132525.3134769)


<div class="article">
<p><span style="color:#062F8E">article</span></p>
</div>
[STEM Blog Article](https://sciencebuffs.org/2018/08/20/cu-boulders-superhuman-lab-is-making-programming-more-accessible/)


## <span style="color:#062F8E">PseudoBlocks</span>
_2016-2017_

Block-based languages are used to teach programming to novices, through the creation of interactive games, stories and animations. However, programs are created using visual representations, which are not accessible to blind and visually impaired users. We designed a non-visual block based language called PseudoBlocks, which uses pseudo-spatial keyboard movements to create programs, and produces audio outputs. In its current form, PseudoBlocks can be used to create simple melodies.

<div class="poster">
<p><span style="color:#062F8E">poster</span></p>
</div>
_An Accessible Blocks Language: Work in Progress_<br>
_**Varsha Koushik** and Clayton Lewis. 2016. An Accessible Blocks Language: Work in Progress. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS '16)._<br>
[ACM abstract](https://dl.acm.org/doi/abs/10.1145/2982142.2982150)

<div class="workshop">
<p><span style="color:#062F8E">workshop</span></p>
</div>
_Work in Progress: A Nonvisual Interface for a Blocks Language_<br>
_**Varsha Koushik** and Clayton Lewis, 2016, VL/HCCThe Psychology of Programming Interest Group (PPIG) 2016_<br>
[paper link](https://ppig.org/papers/2016-ppig-27th-koushik/)

# <span style="color:#B0287B"><u>Accessible Sports Wearable Assistive Technology</u></span>
Today, blind athletes use a tapper to warn them, when they approach the swimming pool wall. The tapper walks along the pool with a long stick with a tennis ball like round object attached to the end of the stick, and taps on the shoulder or the head when blind swimmers approach the pool wall. This approach is inefficient, and it can be expensive to employ a tapper. We designed a wearable activity tracker called Goby, which is worn on the thigh, and uses a downward facing camera to trace the swimmer's position in the pool. Goby detects the black T- shaped line and gives audio feedback to warn the swimmer, when they approach the wall, or swim outside their lane.

<div class="poster">
<p><span style="color: #B0287B">poster</span></p>
</div>
_Goby: A Wearable Swimming Aid for Blind Athletes_<br>
_Annika Muehlbradt, **Varsha Koushik**, and Shaun K. Kane. 2017. Goby: A Wearable Swimming Aid for Blind Athletes. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS '17)._<br>
[ACM abstract](https://dl.acm.org/doi/abs/10.1145/3132525.3134822)

<div class="news">
<p><span style="color: #B0287B">news</span></p>
</div>
CU Boulder Today [ATLAS Expo Article](https://www.colorado.edu/today/2017/05/01/inventions-look-atlas-expo-may-3)<br>
CU Boulder New Venture Challenge Finalist 2017: Social Impact
